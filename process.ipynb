{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcc65b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from QuantConnect import Globals\n",
    "from QuantConnect.Configuration import Config\n",
    "from QuantConnect.Securities import SecurityDefinitionSymbolResolver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132b6f64",
   "metadata": {},
   "source": [
    "### Required environment variables:\n",
    " * __`QC_DATAFLEET_DEPLOYMENT_DATE`__ (date formatted as \"%Y%m%d\")\n",
    " * __`KAVOUT_API_KEY`__\n",
    " * __`KAVOUT_API_HOST`__ (e.g. `google.com:443`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ba1002",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_date = datetime.strptime(os.environ['QC_DATAFLEET_DEPLOYMENT_DATE'], '%Y%m%d')\n",
    "deployment_date_str = deployment_date.strftime('%Y%m%d')\n",
    "\n",
    "api_key = os.environ['KAVOUT_API_KEY']\n",
    "api_host = os.environ['KAVOUT_API_HOST']\n",
    "\n",
    "output_directory = Path(Config.Get('temp-output-directory', '/temp-output-directory'))\n",
    "existing_data_directory = Path(Config.Get('processed-data-directory', Globals.DataFolder))\n",
    "\n",
    "output_file_directory = output_directory / 'alternative' / 'kavout' / 'composite_factor_bundles'\n",
    "existing_data_file_directory = existing_data_directory / 'alternative' / 'kavout' / 'composite_factor_bundles'\n",
    "\n",
    "output_file_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "symbol_resolver = SecurityDefinitionSymbolResolver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5129c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f'https://{api_host}/v2/usa/stock/kavout_quantconnect_factors', verify=False, params={\n",
    "    'token': api_key,\n",
    "    'trade_date__eq': deployment_date.strftime('%Y-%m-%d'),\n",
    "    'size': 10000 # Maximum number of results that can be returned per call, which is more than the size of the universe.\n",
    "})\n",
    "\n",
    "if response.status_code != 200:\n",
    "    raise Exception(f'Failed to download data from host: {api_host} - received {response.status_code} error. Contents: {response.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cce363",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = response.json()\n",
    "if len(json_response) == 0:\n",
    "    raise Exception(f'No results returned from API for date: {deployment_date.date()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af58954",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_count = len(json_response)\n",
    "output_json = []\n",
    "\n",
    "for entry in json_response:\n",
    "    isin = entry['isin_code']\n",
    "    lean_symbol = symbol_resolver.ISIN(isin, deployment_date)\n",
    "    if lean_symbol is None:\n",
    "        continue\n",
    "    \n",
    "    entry['ticker'] = lean_symbol.Value\n",
    "    output_json.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e8159",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(output_json) == 0:\n",
    "    raise Exception('No Symbols found with ISIN lookup')\n",
    "    \n",
    "filtered_count = previous_count - len(output_json)\n",
    "if filtered_count != 0:\n",
    "    print(f'Filtering {filtered_count}/{previous_count} symbols from output data, since no matching ISIN entries were found in the security definitions database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0943c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in output_json:\n",
    "    filename = f'{entry[\"ticker\"].lower()}.csv'\n",
    "    \n",
    "    output_file_path = output_file_directory / filename\n",
    "    existing_data_file_path = existing_data_file_directory / filename\n",
    "    \n",
    "    if not existing_data_file_path.exists():\n",
    "        existing_data_file_path = output_file_path\n",
    "    \n",
    "    output_data = {}\n",
    "    \n",
    "    if existing_data_file_path.exists():\n",
    "        with open(existing_data_file_path, 'r') as existing_data_file:\n",
    "            existing_lines = existing_data_file.read().strip('\\n').split('\\n')\n",
    "            output_data = {line.split(',')[0]: line for line in existing_lines}\n",
    "    \n",
    "    output_data[deployment_date_str] = ','.join([\n",
    "        deployment_date_str,\n",
    "        str(entry['growth']),\n",
    "        str(entry['value']),\n",
    "        str(entry['quality']),\n",
    "        str(entry['momentum']),\n",
    "        str(entry['low_volatility'])\n",
    "    ])\n",
    "    \n",
    "    # Sort the lines we have and output them all to disk, making sure all data is de-duplicated by date.\n",
    "    content = '\\n'.join([i[1] for i in sorted(output_data.items())])\n",
    "    \n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        print(f'Writing data for {entry[\"ticker\"]} to: {output_file_path}')\n",
    "        output_file.write(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
